READ PAPERS



10 Vit: An image is worth 16x16 words: Transformers for image recognition at scale





#### 11 A Question-Answering Approach to Key Value Pair Extraction from Form-like Document Images

专注于提取 Key-Value pairs。首先用 encoder 提取出所有的 Keys，然后将其作为 Query





TODO READ

1 Roberta: A robustly optimized bert pretraining approach

~~2 Vit: An image is worth 16x16 words: Transformers for image recognition at scale~~

~~3 Beit: Bert pre-training of image transformers~~

4 Docformer: End-to-end transformer for document understanding

5 GPT1: Improving language understanding by generative pre-training

6 UNiLm: Unified language model pre-training for natural language understanding and generation

~~7 Layoutxlm: Multimodal pre-training for multilingual visually-rich document understanding~~

8 Deberta: Decoding-enhanced bert with disentangled attention

9 ERNIE: Enhanced Representation through Knowledge Integration

10 ERNIE-Layout: Layout Knowledge Enhanced Pre-training for Visually-rich Document Understanding

~~11 A Question-Answering Approach to Key Value Pair Extraction from Form-like Document Images~~

12 Entity Relation Extraction as Dependency Parsing in Visually Rich Documents

一个 key 对应多个 value





